{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "### Todo lo que se va a leer en este notebook fue inspirado por https://elitedatascience.com/imbalanced-classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 38829 entries, 4886f805 to 80aea0a0\n",
      "Data columns (total 6 columns):\n",
      "cant_conversions               38829 non-null float64\n",
      "cant_checkouts                 38829 non-null float64\n",
      "cant_viewed_product            38829 non-null float64\n",
      "cant_searched_product          38829 non-null float64\n",
      "total_sesiones                 38829 non-null int64\n",
      "promedio_eventos_por_sesion    38829 non-null float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('data/encoding_stats_features.csv', index_col='person')\n",
    "df2 = pd.read_csv('data/viewed_product_stats.csv', index_col='person')\n",
    "df3 = pd.read_csv('data/features_basicas.csv', index_col='person')\n",
    "df4 = pd.read_csv('data/days_elapsed_from_last_event.csv', index_col='person')\n",
    "df5 = pd.read_csv('data/eventos_en_los_ultimos_15_dias.csv', index_col='person')\n",
    "\n",
    "labels = pd.read_csv('data/labels_training_set.csv', index_col='person')\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# joineando df1 con df3\n",
    "df_final = df3.join(df1, how='left', on='person')\n",
    "df_final = df_final.fillna(df_final.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.join(df2, how='left', on='person')\n",
    "df_final = df_final.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.join(df4, how='left', on='person')\n",
    "df_final = df_final.fillna(df_final.max())\n",
    "df_final = df_final.join(df5, how='left', on='person')\n",
    "df_final = df_final.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_final.copy()\n",
    "df_final = df_final.join(labels, how='inner', on='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.949521\n",
       "1    0.050479\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clases desbalanceadas\n",
    "\n",
    "Podemos observar claramente que las clases estan desbalanceadas, vamos a probar distintos métodos para balancearlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    18434\n",
      "Name: label, dtype: int64\n",
      "1    980\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_no_compradores = df_final[df_final.label==0]\n",
    "df_compradores = df_final[df_final.label==1]\n",
    "\n",
    "print(df_no_compradores.label.value_counts())\n",
    "print(df_compradores.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Up-Sample de compradores: \n",
    "\n",
    "Primero voy a probar hacer un up-sample de los compradores, para no achicar mucho el set de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "proporcion_compradores = 0.5\n",
    "\n",
    "df_mas_compradores = resample(df_compradores, \n",
    "                              replace=True,\n",
    "                              n_samples=int(df_no_compradores.label.value_counts()[0] * proporcion_compradores),\n",
    "                              random_state=123)\n",
    "df_upsample = pd.concat([df_mas_compradores, df_no_compradores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Down-Sample de no compradores:\n",
    "\n",
    "Ahora voy a quitar una cierta cantidad de compradores para quedarme con alguna proporción de compradores mayor a la actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "proporcion_compradores = 0.10\n",
    "\n",
    "df_menos_no_compradores = resample(df_no_compradores, \n",
    "                                   replace=True,\n",
    "                                   n_samples=int(df_no_compradores.label.value_counts()[0] * (1-proporcion_compradores)),\n",
    "                                   random_state=123)\n",
    "df_downsample = pd.concat([df_compradores, df_menos_no_compradores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando y comparando\n",
    "\n",
    "La idea ahora es entrenar ambos sets que armamos y comparar con AUC-Score de cada uno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primero vamos a entrenar con el set de datos con compras repetidas (Up-Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_upsample.columns.tolist()\n",
    "features.remove('label')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_upsample[features],\n",
    "                                                    df_upsample['label'], \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=123\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9398446900858614\n"
     ]
    }
   ],
   "source": [
    "rf_us = RandomForestClassifier(n_estimators=60, n_jobs=2, min_samples_split=200,\n",
    "                             random_state=123, class_weight='balanced', max_features=0.6)\n",
    "rf_us.fit(X_train,Y_train)\n",
    "\n",
    "# vemos como le va en el AUC-Score\n",
    "Y_pred = rf_us.predict_proba(X_test)\n",
    "Y_pred_proba = [p[1] for p in Y_pred]\n",
    "print(roc_auc_score(Y_test, Y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahí tenemos el valor del AUC-Score que obtuvimos con el set con compras duplicadas.\n",
    "\n",
    "Ahora vamos a ver otras métricas que también nos importan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.81      0.87      3646\n",
      "          1       0.71      0.91      0.80      1885\n",
      "\n",
      "avg / total       0.86      0.84      0.85      5531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, rf_us.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora vamos a entrenar con el set donde quitamos algunas no compras (Down-Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_downsample.columns.tolist()\n",
    "features.remove('label')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_downsample[features],\n",
    "                                                    df_downsample['label'], \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=123\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8508168494581538\n"
     ]
    }
   ],
   "source": [
    "rf_ds = RandomForestClassifier(n_estimators=30, n_jobs=2, min_samples_split=200,\n",
    "                             random_state=123, class_weight='balanced')\n",
    "rf_ds.fit(X_train,Y_train)\n",
    "\n",
    "# vemos como le va en el AUC-Score\n",
    "Y_pred = rf_ds.predict_proba(X_test)\n",
    "Y_pred_proba = [p[1] for p in Y_pred]\n",
    "print(roc_auc_score(Y_test, Y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos como claramente empeoró el AUC-Score. Ahora veremos como le fué en las otras metricas que estabamos evaluando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.80      0.88      3330\n",
      "          1       0.17      0.74      0.28       184\n",
      "\n",
      "avg / total       0.94      0.80      0.85      3514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, rf_ds.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacer un submit\n",
    "\n",
    "Ahora que comparamos ambas formas de balancear los datos, quiero ver como le va a ir en el submit de kaggle.\n",
    "\n",
    "Voy a usar el dataset con compras repetidas (Up-Sample) ya que es el que mejor AUC-Score me dió."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19415 entries, 4886f805 to 80aea0a0\n",
      "Empty DataFrame"
     ]
    }
   ],
   "source": [
    "df_submit = pd.read_csv('data/trocafone_kaggle_test.csv', low_memory=False, index_col='person')\n",
    "df_events = df_submit.join(df_features, how='inner')\n",
    "df_submit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_pred = rf_us.predict_proba(df_events)\n",
    "proba_de_comprar = [x[1] for x in kaggle_pred]\n",
    "series = pd.Series(proba_de_comprar)\n",
    "df_submit['label'] = series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv('submit.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
